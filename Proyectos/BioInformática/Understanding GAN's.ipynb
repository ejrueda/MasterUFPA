{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LeakyReLU, Reshape\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Jupyter Notebook para entender el modelamiento matemático de las GANs y ponerlo en práctica.</h2></center><br>\n",
    "<b>Autor:</b> Edwin Jahir Rueda Rojas<br>\n",
    "<b>email:</b> ejrueda95g@gmail.com<br>\n",
    "<b>website:</b> edwinrueda.com<br>\n",
    "<b>github:</b> https://github.com/ejrueda<br><br>\n",
    "Todo el contenido aquí realizado se basa en el artículo publicado por Ian J. Goodfellow et al. Titulado: <i><b>Generative Adversarial Nets</b></i>. (https://arxiv.org/abs/1406.2661)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Arquitectura GAN</h1><br>\n",
    "- Se entrenan dos modelos G y D simultaneamente, en los cuales el modelo generativo G captura la distribuición de los datos reales, y el modelo discriminativo D estima la probabilidad de que dado un ejemplo, este sea de la distribuición original o no.\n",
    "\n",
    "#### Objetivo:\n",
    "- El objetivo de esta red es entrenar la red generadora G para maximizar la probabilidad de que la red Discriminadora D cometa errores de intendificación de la distribuición. Esto corresponde a un juego de mini-max entre dos jugadores, y solo existe una única solución, la cual ocurre cuando la red Generadora G capta la distribuición de los datos y así la red Discriminadora D no consigue diferenciar los ejemplos, teniendo así 0.5 de acierto.\n",
    "\n",
    "Cabe aclarar que esto se puede implementar con dos redes perceptrones multicapa utilizando el algoritmo <i>backpropagation</i> para el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo pŕactico\n",
    "- Para nuestro ejemplo práctico, se tomará tomará una base de datos de genes y se trataŕa de generar nuevos genes a partir del modelamiento de la distribuición que aprenderá la red Generadora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red Generadora G\n",
    "- Se toma una distribuición Gaussiana como entrada a la red Generadora para así generar los datos sintéticos (fake).\n",
    "- Con la red generadora lo que se quiere es ir del espació de datos de la distribuición inicial, a el espacio de datos de la distribuición que se quiere replicar, por eso la salida de esta red no es un simple escalar como en un problema de clasificación, esta red tiene como salida los datos que la red cree que pertenecen al espacio original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise_input, out_dim):\n",
    "    \"\"\"\n",
    "    noise_input: vector con los datos de la distribuición inicial\n",
    "    out_dim: dimension de la salida esperada, por ejemplo si es una imagen\n",
    "             en escala de gris, sería out_dim: (32,32,1)\n",
    "    Retorna el modelo Generador\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_shape=(noise_input,)))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(Dropout(.1))\n",
    "    model.add(Dense(np.prod(out_dim), activation=\"tanh\"))\n",
    "    model.add(Reshape(out_dim))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension del ruido de entrada:  100\n"
     ]
    }
   ],
   "source": [
    "noise_input = 100\n",
    "print(\"Dimension del ruido de entrada: \",noise_input)\n",
    "G = generator(noise_input, out_dim=(9,))\n",
    "optimizerG = Adam(lr=0.0004, beta_1=0.5)\n",
    "G.compile(loss='binary_crossentropy', optimizer=optimizerG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 9)                 2313      \n",
      "_________________________________________________________________\n",
      "reshape_12 (Reshape)         (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 28,169\n",
      "Trainable params: 28,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de los datos de entrada: (50, 100)\n",
      "Dimension de los ejemplos generados: (50, 9)\n"
     ]
    }
   ],
   "source": [
    "noise = np.random.normal(loc=0, scale=1, size=(50,100))\n",
    "print(\"Dimension de los datos de entrada:\", noise.shape)\n",
    "data_fake = G.predict(noise)\n",
    "print(\"Dimension de los ejemplos generados:\", data_fake.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red discriminadora D\n",
    "- La red discriminadora funciona como una red clasificadora, la cual tendrá dos categorias, 0 si los datos son de la distribuición real y 1 si los datos vienen de la distribuición falsa (fake)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(input_dim):\n",
    "    \"\"\"\n",
    "    input_dim: dimension de los datos de entrada,\n",
    "               por ejemplo si es una imagen en escala de gris,\n",
    "               sería input_dim: (32,32,1)\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_shape=self.dim))\n",
    "    model.add(LeakyReLU(alpha=0.2)) #función rectificadora\n",
    "    model.add(Dropout(.1))\n",
    "    model.add(Dense(32))\n",
    "    model.add(Flatten())\n",
    "    #activación sigmoid ya que se precisa establecer si es 0 ó 1.\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red GAN\n",
    "- La red GAN está creada conectando tanto la red G como la red D de forma secuencial, recordando que la red D debe ser entrenada de forma separada, para que el algoritmo de <i>backpropagation</i> no afecte los pesos de la red G, asi, una vez la red D se entrene, se procede a entrenar la GAN, la cual mudará solo los pesos de la red G, ya que los de la red D no se pueden actualizar en este paso. Esto se repite la cantidad de <i>epochs</i> que se definan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan():\n",
    "    \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
