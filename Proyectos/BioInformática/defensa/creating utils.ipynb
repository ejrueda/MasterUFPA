{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1> Creating the utils for the project</h1>\n",
    "\n",
    "<b>Autor:</b> Edwin Rueda <br>\n",
    "<b>email:</b> ejrueda95g@gmail.com <br>\n",
    "<b>github:</b> https://github.com/ejrueda <br>\n",
    "<b>website:</b> http://edwinrueda.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scaler\n",
    "- The scaler class make a minmaxscaler operation in a dataframe, this allows that the dataframe keep your index.\n",
    "- Parameters:\n",
    "    - xmin: the min value of the scale\n",
    "    - xmax: the max value of the scale\n",
    "- Equation:\n",
    "    - this scaling is computed by:\n",
    "$$X_{nov} = \\frac{x-min(x)}{max(x) - min(x)} *(x_{max}-x_{min}) + x_{min}$$      \n",
    "\n",
    "    where $x$ represents the dataframe, and $min(x)$ and $max(x)$, represents the minimum and maximum values per column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scaler:\n",
    "    def __init__(self, xmin, xmax):\n",
    "        \"\"\"\n",
    "        minmax scaler from dataframe\n",
    "        \"\"\"\n",
    "        self.xmin = xmin\n",
    "        self.xmax = xmax\n",
    "        self.min_data = False\n",
    "        self.max_data = False\n",
    "        self.flag = False\n",
    "        \n",
    "    def fit(self, X):\n",
    "        self.min_data = np.min(X).values\n",
    "        self.max_data = np.max(X).values\n",
    "        self.flag = True\n",
    "        \n",
    "    def transform(self, X):\n",
    "        assert self.flag, \"Erro de treinamento, primeiro tem que treinar o Scaler, called .fit()\"\n",
    "        X_r = X.copy()\n",
    "        X_r = ((X_r - self.min_data)/(self.max_data - self.min_data))*(self.xmax-self.xmin) + self.xmin\n",
    "        return X_r\n",
    "    \n",
    "    def inverse_transform(self, X):\n",
    "        assert self.flag, \"Erro de treinamento, primeiro tem que treinar o Scaler, called .fit()\"\n",
    "        X_r = X.copy()\n",
    "        X_r = ((X_r - self.xmin)*(self.max_data - self.min_data)/(self.xmax - self.xmin)) + self.min_data\n",
    "        return X_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gan utils\n",
    "- Gan utils is the class to create, train and evaluate the performance of a GAN architecture.\n",
    "\n",
    "- functions:\n",
    "    - <b>train_gan:</b> this fuction combine the generator and discriminator networks and train the gan architecture. Note that this utils implements the tensorflow library, therefore, the G and D networks are not compiled, you just have to pass the networks without compile.\n",
    "        - <b>parameters:</b>\n",
    "            - <b>dataset:</b> a dataset to train the gan architecture, should be a tensorflow dataset.\n",
    "            - <b>G:</b> generator model without training.\n",
    "            - <b>D:</b> discriminator model without training.\n",
    "            - <b>epochs:</b> number of epochs to train de gan architecture.\n",
    "            - <b>batch_size:</b> the size of the batach to train de gan architecture.\n",
    "            - <b>loss_function:</b> the loss funtion, in this case, this architecture should employ the binary_cross_entropy loss functon.\n",
    "        - <b>return:</b>\n",
    "            - <b>accumulated_g_loss:</b> the generator loss by epochs in the architecture.\n",
    "            - <b>accumulated_d_loss:</b> the discriminator loss by epochs in the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gan_utils:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.accumulated_gloss = []\n",
    "        self.accumulated_dloss = []\n",
    "        pass\n",
    "    \n",
    "    def train(self, dataset, G, D, epochs, batch_size, loss_function):\n",
    "        #reset the losses\n",
    "        self.accumulated_gloss = []\n",
    "        self.accumulated_dloss = []\n",
    "        for epoch in range(epochs):\n",
    "            t_i = time()\n",
    "            for batch in dataset:\n",
    "                gen_loss, dis_loss = train_step(batch)\n",
    "                accumulated_dloss.append(dis_loss)\n",
    "                accumulated_gloss.append(gen_loss)\n",
    "            t_f = time()\n",
    "            print(\"epochs[%d:%d] :: G_loss[%f] :: D_loss[%f] :: time:%f[s]\"%(epoch, epochs, gen_loss,\n",
    "                                                                          dis_loss, t_f-t_i))\n",
    "        return accumulated_gloss, accumulated_dloss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.gan_utils"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
